## Day 1 & 2: Software Carpentry, Data Carpentry, and the advanced stream

Over the first two days of the event, two Software Carpentry and one Data Carpentry workshops will run simultaneously. These hands-on workshops will cover basic computer programming concepts and tools for researchers, including program design, version control, data management, and task automation. Participants can elect to participate in either the Python stream or R stream. Both streams will cover git and the command line (bash). 

The Data Carpentry workshop will focus on genomics and bioinformatics tools on the command line.

Simultaneously there will be an advanced stream for those who already have experience with programming or have participated in a Software Carpentry workshop before. This stream is hosted by The Pawsey Supercomputing Centre. Click on the classes' names to see what they are about!

<expandable-heading title="Introduction to PySpark">
This course will cover the basics of the Python API for Spark (PySpark).
</expandable-heading>

<expandable-heading title="Nimbus research cloud training">
At the end of this session students will know how to launch and maintain a virtual machine on the Pawsey Nimbus research cloud.  
</expandable-heading>

<expandable-heading title="Serial Optimisation">
This course covers the various aspects of achieving good performance from serial code; including algorithm, programming, profiling, and optimisation considerations. 
</expandable-heading>

<expandable-heading title="Remote Visualisation">
This course covers various approaches to visualising large data sets using the Zeus cluster at the Pawsey Supercomputing Centre.
</expandable-heading>

At the end of day 2 MP [Dr. Anne Aly][aa] will hold a keynote on the future of data and the role of the government!


[aa]: https://en.wikipedia.org/wiki/Anne_Aly
